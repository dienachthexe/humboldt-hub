name: Automagical Multi-Collection Harvest

on:
  workflow_dispatch: {}

jobs:
  harvest:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Hub
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install sickle

      - name: Run Precision Harvest
        shell: bash
        run: |
          python <<'PYCODE'
          from sickle import Sickle
          import csv
          import xml.etree.ElementTree as ET
          import glob
          import sys

          CONFIG_PATH = 'repository_config.csv'
          OUTPUT_CSV  = 'master.csv'

          # Blacklist remains the same
          exact_blacklist = [
              'alra','apportionment','authorresources','booger','botany_jps',
              'cahssnews','capstone','careercurriculumconnections','ccv',
              'chanterelle','clubnews','comm300','conferences','contaminated_sites',
              'courageouscuentos','creative_pub','crp','csucompetitionvideos',
              'csuglobalaction','csuglobaljournal','culturaltimes','data','digitallab',
              'esmproject','etd','etd_slideshow','faculty','facultypub','fiction',
              'foodfutures','gradnews','gradslam','gspproject','h5ii','hb_infrastructure',
              'hb_sustainability','hcapc','hcapc_aerial','hcapc_index','herbarium_photos',
              'histpaper','hjm','hjsr','hjsrvideo','homepage_gallery','hsuslri',
              'hsuslri_geospatial','hsuslri_local','hsuslri_presentations','hsuslri_state',
              'hsuslri_student','humboldtgeographic','humnews','ideafest-events','ije',
              'inrsep_posters','internationalnews','interviews','isfsi','isfsi_geospatial',
              'isfsi_local','isfsi_presentations','isfsi_state','isfsi_student','journals',
              'jscc_conference','jscc_student','librarian','library_pub','librarypub',
              'math','monographs','msw','oceanogrpahypub','odeinews','oer',
              'oer_sustainability','open_ed','pelicanbayresearchjournal','personas',
              'physicssims','politics','polyarc','posters','pracademics','press',
              'projectrebound','projects','proposals','rectourism','reprint','rr','rrv',
              'rspnews','rwc','senior_cd','senior_comm','senior_crgs','senior_esm',
              'senior_ffrm','senior_hist','senior_math','senior_soc','sotl_ip','student',
              'studentcomm','studenthist','studentresearchbio','studentscholar',
              'sustainability','telonichernews','textbooks','theosprey','theosprey1970s',
              'theosprey1980s','theosprey1990s','theosprey2000s','theosprey2010s',
              'theosprey2020s','toyon','toyonv','unconference','wildlife_posters',
              'world','worlddahs','worlddahsimages','worlddahsimages-2019-2020',
              'worldwlc','worldwlcimages','worldwlcimages-2019-2020','worldwlcimages-sp19',
              'wrrap','xavhumboldt','yesv','zerowaste'
          ]

          def safe_join(values):
              return ' ; '.join(v for v in values if v).strip()

          def get_marc(rec, tag, code):
              f = rec.find(f".//*[@tag='{tag}']")
              if f is None: return ''
              subs = [sf.text for sf in f.findall(f".//*[@code='{code}']") if sf.text]
              return ' '.join(subs).strip()

          try:
              with open(CONFIG_PATH, mode='r', encoding='utf-8-sig') as f:
                  config_list = list(csv.DictReader(f))
          except Exception as e:
              print(f"Error reading config: {e}")
              sys.exit(1)

          all_rows = []
          header = ['Title','Description','Subject','Date','Collection','Institution','Thumbnail','Link']

          for repo in config_list:
              ptype = (repo.get('Platform_Type') or '').strip()
              base  = repo.get('Base_URL')
              prefix = repo.get('Prefix')

              if ptype == 'DigitalCommons':
                  print(f"Starting DigitalCommons harvest from {base}...")
                  try:
                      sickle = Sickle(base)
                      sets = [s for s in sickle.ListSets()]
                      for s in sets:
                          raw = s.setSpec.strip()
                          tail = raw.split(':')[-1]
                          if (raw not in exact_blacklist) and (tail not in exact_blacklist):
                              try:
                                  records = sickle.ListRecords(metadataPrefix=prefix, set=raw, ignore_deleted=True)
                                  for record in records:
                                      m = record.metadata
                                      title = safe_join(m.get(repo['Title_Field'], []))
                                      desc = safe_join([u for u in m.get(repo['Description_Field'], []) if not (isinstance(u, str) and u.lower().endswith('.jpg'))])
                                      subj = safe_join(m.get(repo['Subject_Field'], []))
                                      date = safe_join(m.get(repo['Date_Field'], []))
                                      coll = safe_join(m.get(repo['Collection_Field'], []))
                                      thumb = next((u for u in m.get('description', []) if isinstance(u, str) and '.jpg' in u), 'https://img.icons8.com/color/96/document.png')
                                      link = next((u for u in m.get('identifier', []) if isinstance(u, str) and 'humboldt.edu' in u and '.jpg' not in u), '')
                                      all_rows.append([title, desc, subj, date, coll, repo['Institution_Name'], thumb, link])
                              except Exception as e:
                                  print(f"Skipping set {raw}: {e}")
                  except Exception as e:
                      print(f"Critical DC Error: {e}")

              elif ptype == 'CONTENTdm':
                  print("Starting CONTENTdm harvest...")
                  try:
                      sickle = Sickle(base)
                      # No limit here
                      records = sickle.ListRecords(metadataPrefix=prefix, set='palmquistyale', ignore_deleted=True)
                      for record in records:
                          m = record.metadata
                          sid = record.header.identifier.split('/')[-1]
                          all_rows.append([
                              safe_join(m.get(repo['Title_Field'], [])),
                              safe_join([u for u in m.get(repo['Description_Field'], []) if not (isinstance(u, str) and u.lower().endswith('.jpg'))]),
                              safe_join(m.get(repo['Subject_Field'], [])),
                              safe_join(m.get(repo['Date_Field'], [])),
                              safe_join(m.get(repo['Collection_Field'], [])),
                              repo['Institution_Name'],
                              repo['Thumbnail_Pattern'].format(setSpec='palmquistyale', id=sid),
                              repo['Link_Pattern'].format(setSpec='palmquistyale', id=sid)
                          ])
                  except Exception as e:
                      print(f"CONTENTdm Error: {e}")

              elif 'Archives' in ptype:
                  print("Processing local Archives XML files...")
                  for xml_file in glob.glob('finding*.xml'):
                      try:
                          tree = ET.parse(xml_file)
                          root = tree.getroot()
                          marcs = root.findall('.//record') or root.findall('.//{http://www.loc.gov/MARC21/slim}record')
                          for record in marcs:
                              f008 = record.find(".//*[@tag='008']")
                              date = f008.text[7:11] if (f008 is not None and f008.text and len(f008.text) >= 11) else ''
                              f001 = record.find(".//*[@tag='001']")
                              mms_id = f001.text if f001 is not None else ''
                              all_rows.append([
                                  get_marc(record, '245', 'a'),
                                  get_marc(record, '520', 'a'),
                                  get_marc(record, '650', 'a'),
                                  date,
                                  get_marc(record, '710', 'a'),
                                  repo['Institution_Name'],
                                  'https://img.icons8.com/color/96/folder-invoices--v1.png',
                                  repo['Link_Pattern'].format(mms_id=mms_id) if mms_id else ''
                              ])
                      except Exception as e:
                          print(f"XML Error in {xml_file}: {e}")

          with open(OUTPUT_CSV, 'w', newline='\n', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerow(header)
              writer.writerows(all_rows)
          print(f"Success! Harvested {len(all_rows)} total records.")
          PYCODE

      - name: Commit master.csv if changed
        shell: bash
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add master.csv
          if git diff --staged --quiet; then
            echo "No changes"
          else
            git commit -m "Full harvest: $(date)"
            git pull --rebase
            git push
          fi