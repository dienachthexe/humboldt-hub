name: Palmquist & Finding Aids & Oral History Harvest
on:
  workflow_dispatch:

jobs:
  harvest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Hub
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Sickle
        run: pip install sickle

      - name: Run Triple Harvest
        run: |
          python -c "
          from sickle import Sickle
          import csv
          import xml.etree.ElementTree as ET
          import glob
          
          all_data = []

          # --- PART 1: CONTENTdm (Photos) ---
          try:
              sickle_cdm = Sickle('https://cdm16166.contentdm.oclc.org/oai/oai.php')
              records = sickle_cdm.ListRecords(metadataPrefix='oai_dc', set='palmquistyale', ignore_deleted=True)
              for i, record in enumerate(records):
                  if i >= 100: break
                  m = record.metadata
                  sid = record.header.identifier.split('/')[-1]
                  # ALL fields joined by space for tokenization
                  all_data.append([
                      ' '.join(m.get('title', [])).replace(':', '').strip(),
                      ' '.join(m.get('creator', [])),
                      ' '.join(m.get('date', [])),
                      ' '.join(m.get('description', [])),
                      ' '.join(m.get('subject', [])),
                      ' '.join(m.get('coverage', [])),
                      ' '.join(m.get('rights', [])),
                      f'https://cdm16166.contentdm.oclc.org/utils/getthumbnail/collection/palmquistyale/id/{sid}',
                      f'https://cdm16166.contentdm.oclc.org/digital/collection/palmquistyale/id/{sid}'
                  ])
          except Exception as e: print(f'CONTENTdm Error: {e}')

          # --- PART 2: DigitalCommons (Oral Histories) ---
          try:
              sickle_dc = Sickle('https://digitalcommons.humboldt.edu/do/oai/')
              dc_records = sickle_dc.ListRecords(metadataPrefix='oai_dc', set='publication:old_timers', ignore_deleted=True)
              for record in dc_records:
                  m = record.metadata
                  desc_list = m.get('description', [])
                  formal_title = m.get('title', [''])[0]
                  display_title = next((d for d in desc_list if 'Interview' in d), formal_title).replace(':', '').strip()
                  
                  ids = m.get('identifier', [])
                  link = next((i for i in ids if 'digitalcommons.humboldt.edu/old_timers/' in i and 'thumbnail' not in i), '')
                  thumb = next((i for i in ids if 'thumbnail.jpg' in i), 'https://img.icons8.com/color/96/microphone.png')
                  
                  all_data.append([
                      display_title,
                      ' '.join(m.get('creator', [])),
                      ' '.join(m.get('date', [])),
                      ' '.join(desc_list), # Full description now searchable
                      'Oral History ' + ' '.join(m.get('subject', [])),
                      'DigitalCommons',
                      'Cal Poly Humboldt Library',
                      thumb,
                      link
                  ])
          except Exception as e: print(f'DigitalCommons Error: {e}')

          # --- PART 3: MARCXML (Finding Aids) ---
          xml_files = glob.glob('finding*.xml')
          if xml_files:
              tree = ET.parse(xml_files[0])
              root = tree.getroot()
              marcs = root.findall('.//record') or root.findall('.//{http://www.loc.gov/MARC21/slim}record')
              for record in marcs:
                  t_field = record.find(\".//*[@tag='245']\")
                  title = 'Unknown Finding Aid'
                  if t_field is not None:
                      a = t_field.find(\"./*[@code='a']\")
                      b = t_field.find(\"./*[@code='b']\")
                      title = f\"{a.text if a is not None else ''} {b.text if b is not None else ''}\".replace(':', '').strip()
                  
                  # Subject Expansion (600, 610, 650, 651) for keyword richness
                  subjects = []
                  for tag in ['600', '610', '650', '651']:
                      fields = record.findall(f\".//*[@tag='{tag}']\")
                      for f in fields:
                          subfields = f.findall(\"./*[@code='a']\")
                          subjects.extend([sf.text for sf in subfields if sf.text])
                  
                  id_f = record.find(\".//*[@tag='001']\")
                  mms_id = id_f.text if id_f is not None else '0'
                  d_field = record.find(\".//*[@tag='520']\")
                  desc = d_field.find(\"./*[@code='a']\").text if d_field is not None else 'Archival collection finding aid.'
                  
                  link = f'https://csu-humboldt.primo.exlibrisgroup.com/permalink/01CALS_HUL/omcour/alma{mms_id}'
                  all_data.append([title, 'Archives', 'Multiple Dates', desc, ' '.join(subjects), 'Finding Aid', 'Rights Reserved', 'https://img.icons8.com/color/96/folder-invoices--v1.png', link])

          with open('master.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerow(['Title', 'Creator', 'Date', 'Description', 'Subject', 'Coverage', 'Rights', 'Thumbnail', 'Link'])
              writer.writerows(all_data)
          "
      - name: Save to GitHub
        run: |
          git config --global user.name 'humboldt-hub-robot'
          git config --global user.email 'robot@humboldt-hub.local'
          git add master.csv
          git commit -m "Global keyword search optimization for all fields" || exit 0
          git push