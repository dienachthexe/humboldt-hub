name: Automagical Multi-Collection Harvest
on:
  workflow_dispatch:

jobs:
  harvest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Hub
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Sickle
        run: pip install sickle

      - name: Run Precision Harvest
        run: |
          python -c "
          from sickle import Sickle
          import csv
          import xml.etree.ElementTree as ET
          import glob
          
          all_data = []
          
          # Exact blacklist for DigitalCommons discovery
          exact_blacklist = [
              'alra', 'apportionment', 'authorresources', 'booger', 'botany_jps', 
              'cahssnews', 'capstone', 'careercurriculumconnections', 'ccv', 
              'chanterelle', 'clubnews', 'comm300', 'conferences', 'contaminated_sites',
              'courageouscuentos', 'creative_pub', 'crp', 'csucompetitionvideos', 
              'csuglobalaction', 'csuglobaljournal', 'culturaltimes', 'data', 'digitallab',
              'esmproject', 'etd', 'etd_slideshow', 'faculty', 'facultypub', 'fiction',
              'foodfutures', 'gradnews', 'gradslam', 'gspproject', 'h5ii', 'hb_infrastructure',
              'hb_sustainability', 'hcapc', 'hcapc_aerial', 'hcapc_index', 'herbarium_photos',
              'histpaper', 'hjm', 'hjsr', 'hjsrvideo', 'homepage_gallery', 'hsuslri', 
              'hsuslri_geospatial', 'hsuslri_local', 'hsuslri_presentations', 'hsuslri_state',
              'hsuslri_student', 'humboldtgeographic', 'humnews', 'ideafest-events', 'ije',
              'inrsep_posters', 'internationalnews', 'interviews', 'isfsi', 'isfsi_geospatial',
              'isfsi_local', 'isfsi_presentations', 'isfsi_state', 'isfsi_student', 'journals',
              'jscc_conference', 'jscc_student', 'librarian', 'library_pub', 'librarypub',
              'math', 'monographs', 'msw', 'oceanogrpahypub', 'odeinews', 'oer', 
              'oer_sustainability', 'open_ed', 'pelicanbayresearchjournal', 'personas',
              'physicssims', 'politics', 'polyarc', 'posters', 'pracademics', 'press',
              'projectrebound', 'projects', 'proposals', 'rectourism', 'reprint', 'rr', 'rrv',
              'rspnews', 'rwc', 'senior_cd', 'senior_comm', 'senior_crgs', 'senior_esm',
              'senior_ffrm', 'senior_hist', 'senior_math', 'senior_soc', 'sotl_ip', 'student',
              'studentcomm', 'studenthist', 'studentresearchbio', 'studentscholar', 
              'sustainability', 'telonichernews', 'textbooks', 'theosprey', 'theosprey1970s',
              'theosprey1980s', 'theosprey1990s', 'theosprey2000s', 'theosprey2010s', 
              'theosprey2020s', 'toyon', 'toyonv', 'unconference', 'wildlife_posters', 
              'world', 'worlddahs', 'worlddahsimages', 'worlddahsimages-2019-2020', 
              'worldwlc', 'worldwlcimages', 'worldwlcimages-2019-2020', 'worldwlcimages-sp19', 
              'wrrap', 'xavhumboldt', 'yesv', 'zerowaste'
          ]

          def get_marc(rec, tag, code):
              ns = {'m': 'http://www.loc.gov/MARC21/slim'}
              f = rec.find(f\".//*[@tag='{tag}']\")
              if f is None: return ''
              return ' '.join([sf.text for sf in f.findall(f\".//*[@code='{code}']\") if sf.text])

          with open('repository_config.csv', mode='r', encoding='utf-8-sig') as f:
              reader = csv.DictReader(f)
              config_list = list(reader)

          for repo in config_list:
              ptype = repo['Platform_Type']
              
              if ptype == 'DigitalCommons':
                  try:
                      sickle = Sickle(repo['Base_URL'])
                      all_sets = [s.setSpec for s in sickle.ListSets() if s.setSpec.replace('publication:','') not in exact_blacklist]
                      for set_spec in all_sets:
                          records = sickle.ListRecords(metadataPrefix=repo['Prefix'], set=set_spec, ignore_deleted=True)
                          for i, record in enumerate(records):
                              if i >= 50: break
                              m = record.metadata
                              thumb = next((u for u in m.get('description', []) if '.jpg' in u), 'https://img.icons8.com/color/96/document.png')
                              link = next((u for u in m.get('identifier', []) if 'humboldt.edu' in u and '.jpg' not in u), '')
                              all_data.append([
                                  ' ; '.join(m.get(repo['Title_Field'], [])).strip(),
                                  ' ; '.join(m.get(repo['Description_Field'], [])),
                                  ' ; '.join(m.get(repo['Subject_Field'], [])),
                                  ' ; '.join(m.get(repo['Date_Field'], [])),
                                  ' ; '.join(m.get(repo['Collection_Field'], [])),
                                  repo['Institution_Name'], thumb, link
                              ])
                  except: pass

              elif ptype == 'CONTENTdm':
                  try:
                      sickle = Sickle(repo['Base_URL'])
                      records = sickle.ListRecords(metadataPrefix=repo['Prefix'], set='palmquistyale', ignore_deleted=True)
                      for i, record in enumerate(records):
                          if i >= 100: break
                          m = record.metadata
                          sid = record.header.identifier.split('/')[-1]
                          all_data.append([
                              ' ; '.join(m.get(repo['Title_Field'], [])).strip(),
                              ' ; '.join(m.get(repo['Description_Field'], [])),
                              ' ; '.join(m.get(repo['Subject_Field'], [])),
                              ' ; '.join(m.get(repo['Date_Field'], [])),
                              ' ; '.join(m.get(repo['Collection_Field'], [])),
                              repo['Institution_Name'],
                              repo['Thumbnail_Pattern'].format(setSpec='palmquistyale', id=sid),
                              repo['Link_Pattern'].format(setSpec='palmquistyale', id=sid)
                          ])
                  except: pass

              elif 'Archives' in ptype:
                  for xml_file in glob.glob('finding*.xml'):
                      tree = ET.parse(xml_file)
                      root = tree.getroot()
                      marcs = root.findall('.//record') or root.findall('.//{http://www.loc.gov/MARC21/slim}record')
                      for record in marcs:
                          f008 = record.find(\".//*[@tag='008']\")
                          date = f008.text[7:11] if f008 is not None else ''
                          mms_id = record.find(\".//*[@tag='001']\").text
                          all_data.append([
                              get_marc(record, '245', 'a'),
                              get_marc(record, '520', 'a'),
                              get_marc(record, '650', 'a'),
                              date,
                              get_marc(record, '710', 'a'),
                              repo['Institution_Name'],
                              'https://img.icons8.com/color/96/folder-invoices--v1.png',
                              repo['Link_Pattern'].format(mms_id=mms_id)
                          ])

          with open('master.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerow(['Title', 'Description', 'Subject', 'Date', 'Collection', 'Institution', 'Thumbnail', 'Link'])
              writer.writerows(all_data)
          "
      - name: Save to GitHub
        run: |
          git config --global user.name 'humboldt-hub-robot'
          git config --global user.email 'robot@humboldt-hub.local'
          git add master.csv
          git commit -m "Sync master.csv with repository_config crosswalk" || exit 0
          git push