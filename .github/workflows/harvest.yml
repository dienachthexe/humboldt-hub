name: Automagical Multi-Collection Harvest
on:
  workflow_dispatch:

jobs:
  harvest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Hub
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Sickle
        run: pip install sickle

      - name: Run Automagical Harvest
        run: |
          python -c "
          from sickle import Sickle
          import csv
          import xml.etree.ElementTree as ET
          import glob
          
          all_data = []
          
          # 1. THE PATTERN BLACKLIST
          # Only these three specific series use pattern matching to catch future years.
          pattern_list = ['studentnewspaper', 'ellenadornews', 'ideafest']

          # 2. THE EXACT LIST (Transcribed from your provided list)
          # These are exact matches. If the setSpec is exactly this, it is skipped.
          exact_blacklist = [
              'booger', 'botany_jps', 'cahssnews', 'capstone', 'careercurriculumconnections',
              'ccv', 'chanterelle', 'clubnews', 'comm300', 'conferences', 'contaminated_sites',
              'courageouscuentos', 'creative_pub', 'crp', 'csucompetitionvideos', 
              'csuglobalaction', 'csuglobaljournal', 'culturaltimes', 'data', 'digitallab',
              'esmproject', 'etd', 'etd_slideshow', 'faculty', 'facultypub', 'fiction',
              'foodfutures', 'gradnews', 'gradslam', 'gspproject', 'h5ii', 'hb_infrastructure',
              'hb_sustainability', 'hcapc', 'hcapc_aerial', 'hcapc_index', 'herbarium_photos',
              'histpaper', 'hjm', 'hjsr', 'hjsrvideo', 'homepage_gallery', 'hsuslri', 
              'hsuslri_geospatial', 'hsuslri_local', 'hsuslri_presentations', 'hsuslri_state',
              'hsuslri_student', 'humboldtgeographic', 'humnews', 'ideafest-events', 'ije',
              'inrsep_posters', 'internationalnews', 'interviews', 'isfsi', 'isfsi_geospatial',
              'isfsi_local', 'isfsi_presentations', 'isfsi_state', 'isfsi_student', 'journals',
              'jscc_conference', 'jscc_student', 'librarian', 'library_pub', 'librarypub',
              'math', 'monographs', 'msw', 'oceanogrpahypub', 'odeinews', 'oer', 
              'oer_sustainability', 'open_ed', 'pelicanbayresearchjournal', 'personas',
              'physicssims', 'politics', 'polyarc', 'posters', 'pracademics', 'press',
              'projectrebound', 'projects', 'proposals', 'rectourism', 'reprint', 'rr', 'rrv',
              'rspnews', 'rwc', 'senior_cd', 'senior_comm', 'senior_crgs', 'senior_esm',
              'senior_ffrm', 'senior_hist', 'senior_math', 'senior_soc', 'sotl_ip', 'student',
              'studentcomm', 'studenthist', 'studentresearchbio', 'studentscholar', 
              'sustainability', 'telonichernews', 'textbooks', 'theosprey', 'theosprey1970s',
              'theosprey1980s', 'theosprey1990s', 'theosprey2000s', 'theosprey2010s', 
              'theosprey2020s', 'toyon', 'toyonv', 'unconference', 'wildlife_posters', 
              'world', 'worlddahs', 'worlddahsimages', 'worlddahsimages-2019-2020', 
              'worldwlc', 'worldwlcimages', 'worldwlcimages-2019-2020', 'worldwlcimages-sp19', 
              'wrrap', 'xavhumboldt', 'yesv', 'zerowaste'
          ] 

          # --- PART 1: DigitalCommons ---
          try:
              sickle_dc = Sickle('https://digitalcommons.humboldt.edu/do/oai/')
              all_sets = sickle_dc.ListSets()
              
              for s in all_sets:
                  # Standardize ID (strip 'publication:' prefix if present for matching)
                  full_sid = s.setSpec.lower()
                  short_sid = full_sid.replace('publication:', '')
                  
                  # PATTERN LOGIC: Check for our three specific year-based patterns
                  is_pattern_match = any(p in short_sid for p in pattern_list)
                  
                  # EXCEPTION: Protect the parent collections even if they match the pattern
                  is_protected_parent = short_sid in ['studentnewspaper', 'ellenador', 'ideafest']
                  
                  if is_pattern_match and not is_protected_parent:
                      continue

                  # EXACT LIST LOGIC: Check against your specific list
                  if short_sid in exact_blacklist:
                      continue
                  
                  if 'publication:' in full_sid:
                      print(f'Harvesting: {s.setName}')
                      try:
                          records = sickle_dc.ListRecords(metadataPrefix='oai_dc', set=full_sid, ignore_deleted=True)
                          for i, record in enumerate(records):
                              if i >= 50: break 
                              m = record.metadata
                              subjects = []
                              for sub in m.get('subject', []):
                                  subjects.extend([item.strip() for item in sub.split(',')])
                              
                              all_data.append([
                                  ' ; '.join(m.get('title', [])).replace(':', '').strip(),
                                  ' ; '.join(m.get('creator', []) + m.get('contributor', [])),
                                  ' ; '.join(m.get('description', [])),
                                  ' ; '.join(list(set(subjects))),
                                  'DigitalCommons', 'Cal Poly Humboldt',
                                  next((id for id in m.get('identifier', []) if 'thumbnail.jpg' in id), 'https://img.icons8.com/color/96/document.png'),
                                  next((id for id in m.get('identifier', []) if 'digitalcommons.humboldt.edu' in id and 'thumbnail' not in id), '')
                              ])
                      except Exception: pass
          except Exception as e: print(f'DC Error: {e}')

          # --- PART 2: CONTENTdm ---
          try:
              sickle_cdm = Sickle('https://cdm16166.contentdm.oclc.org/oai/oai.php')
              records = sickle_cdm.ListRecords(metadataPrefix='oai_dc', set='palmquistyale', ignore_deleted=True)
              for i, record in enumerate(records):
                  if i >= 100: break
                  m = record.metadata
                  sid = record.header.identifier.split('/')[-1]
                  all_data.append([
                      ' ; '.join(m.get('title', [])).replace(':', '').strip(),
                      ' ; '.join(m.get('creator', [])),
                      ' ; '.join(m.get('description', [])),
                      ' ; '.join(m.get('subject', [])),
                      'CONTENTdm', 'Cal Poly Humboldt',
                      f'https://cdm16166.contentdm.oclc.org/utils/getthumbnail/collection/palmquistyale/id/{sid}',
                      f'https://cdm16166.contentdm.oclc.org/digital/collection/palmquistyale/id/{sid}'
                  ])
          except Exception: pass

          # --- PART 3: MARCXML ---
          for xml_file in glob.glob('finding*.xml'):
              tree = ET.parse(xml_file)
              root = tree.getroot()
              marcs = root.findall('.//record') or root.findall('.//{http://www.loc.gov/MARC21/slim}record')
              for record in marcs:
                  t_field = record.find(\".//*[@tag='245']\")
                  title = ' '.join([sf.text for sf in t_field.findall('./*') if sf.text]) if t_field is not None else 'Unknown'
                  subjects = []
                  for tag in ['600', '610', '650', '651']:
                      for f in record.findall(f\".//*[@tag='{tag}']\"):
                          subjects.extend([sf.text for sf in f.findall(\"./*[@code='a']\") if sf.text])
                  id_f = record.find(\".//*[@tag='001']\")
                  mms_id = id_f.text if id_f is not None else '0'
                  d_field = record.find(\".//*[@tag='520']\")
                  desc = d_field.find(\"./*[@code='a']\").text if d_field is not None else 'Archival collection finding aid.'
                  link = f'https://csu-humboldt.primo.exlibrisgroup.com/permalink/01CALS_HUL/omcour/alma{mms_id}'
                  all_data.append([title.replace(':', '').strip(), 'Archives', desc, ' ; '.join(subjects), 'Alma', 'Humboldt Special Collections', 'https://img.icons8.com/color/96/folder-invoices--v1.png', link])

          # --- PART 4: SAVE ---
          with open('master.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerow(['Title', 'Creator', 'Description', 'Subject', 'Source', 'Publisher', 'Thumbnail', 'Link'])
              writer.writerows(all_data)
          "
      - name: Save to GitHub
        run: |
          git config --global user.name 'humboldt-hub-robot'
          git config --global user.email 'robot@humboldt-hub.local'
          git add master.csv
          git commit -m "Final Precision Blacklist Run" || exit 0
          git push