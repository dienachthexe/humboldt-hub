name: Palmquist & Finding Aids Harvest
on:
  workflow_dispatch:

jobs:
  harvest:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Hub
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Install Sickle
        run: pip install sickle

      - name: Run Dual Harvest
        run: |
          python -c "
          from sickle import Sickle
          import csv
          import xml.etree.ElementTree as ET
          import glob
          
          all_data = []

          # --- PART 1: CONTENTdm HARVEST ---
          print('Starting CONTENTdm harvest...')
          try:
              sickle = Sickle('https://cdm16166.contentdm.oclc.org/oai/oai.php')
              records = sickle.ListRecords(metadataPrefix='oai_dc', set='palmquistyale', ignore_deleted=True)
              
              for i, record in enumerate(records):
                  if i >= 100: break
                  m = record.metadata
                  system_id = record.header.identifier.split('/')[-1]
                  
                  all_data.append([
                      ' ; '.join(m.get('title', [])),
                      ' ; '.join(m.get('creator', [])),
                      ' ; '.join(m.get('date', [])),
                      ' ; '.join(m.get('description', [])),
                      ' ; '.join(m.get('subject', [])),
                      ' ; '.join(m.get('coverage', [])),
                      ' ; '.join(m.get('rights', [])),
                      f'https://cdm16166.contentdm.oclc.org/utils/getthumbnail/collection/palmquistyale/id/{system_id}',
                      f'https://cdm16166.contentdm.oclc.org/digital/collection/palmquistyale/id/{system_id}'
                  ])
              print(f'Successfully harvested {len(all_data)} photos.')
          except Exception as e:
              print(f'Notice: CONTENTdm harvest skipped or failed: {e}')

          # --- PART 2: MARCXML HARVEST ---
          xml_files = glob.glob('finding*.xml')
          if not xml_files:
              print('ERROR: No XML file starting with finding found!')
          else:
              target_file = xml_files[0]
              print(f'Found XML file: {target_file}. Starting translation...')
              tree = ET.parse(target_file)
              root = tree.getroot()
              
              marcs = root.findall('.//record')
              if not marcs:
                  ns = {'m': 'http://www.loc.gov/MARC21/slim'}
                  marcs = root.findall('.//m:record', ns)

              for record in marcs:
                  t_field = record.find(\".//datafield[@tag='245']\")
                  title = 'Unknown Finding Aid'
                  if t_field is not None:
                      a = t_field.find(\"subfield[@code='a']\")
                      b = t_field.find(\"subfield[@code='b']\")
                      title = f\"{a.text if a is not None else ''} {b.text if b is not None else ''}\".strip()
                  
                  id_field = record.find(\".//controlfield[@tag='001']\")
                  mms_id = id_field.text if id_field is not None else '0'
                  
                  d_field = record.find(\".//datafield[@tag='520']\")
                  desc = 'Archival collection finding aid.'
                  if d_field is not None:
                      d_sub = d_field.find(\"subfield[@code='a']\")
                      if d_sub is not None: desc = d_sub.text
                  
                  # UPDATED PRIMO PERMALINK STRUCTURE
                  link = f'https://csu-humboldt.primo.exlibrisgroup.com/permalink/01CALS_HUL/omcour/alma{mms_id}'
                  icon = 'https://img.icons8.com/color/96/folder-invoices--v1.png'
                  
                  all_data.append([title, 'Archives', 'Multiple Dates', desc, 'Finding Aid', 'Humboldt County', 'Check Finding Aid for Rights', icon, link])
              print(f'Successfully added {len(marcs)} finding aids.')

          # --- PART 3: SAVE TO CSV ---
          with open('master.csv', 'w', newline='', encoding='utf-8') as f:
              writer = csv.writer(f)
              writer.writerow(['Title', 'Creator', 'Date', 'Description', 'Subject', 'Coverage', 'Rights', 'Thumbnail', 'Link'])
              writer.writerows(all_data)
          "
      - name: Save to GitHub
        run: |
          git config --global user.name 'humboldt-hub-robot'
          git config --global user.email 'robot@humboldt-hub.local'
          git add master.csv
          git commit -m "Merged Finding Aids and Photos with corrected Permalink URL" || exit 0
          git push